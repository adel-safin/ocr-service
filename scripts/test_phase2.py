#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –§–∞–∑—ã 2: –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
"""
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ—Ä–Ω—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ –ø—É—Ç—å
app_root = Path(__file__).parent.parent
if str(app_root) not in sys.path:
    sys.path.insert(0, str(app_root))

from core.processor import DocumentPipeline
from utils.dataset_loader import DatasetLoader
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_ml_components():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
    print("\n" + "=" * 80)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –§–ê–ó–´ 2: –ú–ê–®–ò–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï")
    print("=" * 80)
    
    # –¢–µ—Å—Ç 1: –†–∞–±–æ—Ç–∞ —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º
    print("\nüî¨ –¢–ï–°–¢ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞")
    print("-" * 80)
    
    dataset_root = Path("../–î–∞—Ç–∞—Å–µ—Ç")
    loader = DatasetLoader(str(dataset_root))
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    doc_types = loader.get_all_document_types()
    print(f"üìã –ù–∞–π–¥–µ–Ω–æ —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(doc_types)}")
    for i, doc_type in enumerate(doc_types[:10], 1):
        print(f"   {i}. {doc_type}")
    
    # –ü–æ–∏—Å–∫ –ø–∞—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    print("\nüîç –ü–æ–∏—Å–∫ –ø–∞—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ + —ç—Ç–∞–ª–æ–Ω)...")
    pairs = loader.find_document_pairs("–ê–∫—Ç –ê–û–°–†")
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä: {len(pairs)}")
    
    if pairs:
        print("\n–ü—Ä–∏–º–µ—Ä—ã –ø–∞—Ä:")
        for i, pair in enumerate(pairs[:3], 1):
            print(f"   {i}. {pair['base_name']}")
            print(f"      –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {Path(pair['image_path']).name}")
            print(f"      –≠—Ç–∞–ª–æ–Ω: {Path(pair['reference_path']).name}")
    
    # –¢–µ—Å—Ç 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å ML
    print("\n\nüî¨ –¢–ï–°–¢ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏")
    print("-" * 80)
    
    if pairs:
        test_file = pairs[0]['image_path']
        print(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞: {Path(test_file).name}")
        
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å ML (–§–∞–∑–∞ 2)
            pipeline = DocumentPipeline(use_ml=True, use_active_learning=False)
            
            print("\n‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏...")
            result = pipeline.process(
                file_path=test_file,
                template="–ê–∫—Ç –ê–û–°–†",
                required_fields=["ogrn", "inn", "date"]
            )
            
            # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            print("\n" + "-" * 80)
            print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –° ML")
            print("-" * 80)
            
            print(f"\n‚úÖ Document ID: {result['document_id']}")
            print(f"üìä –ö–∞—á–µ—Å—Ç–≤–æ: {result['quality_report']['overall_quality']:.2%}")
            print(f"üîç –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å OCR: {result['quality_report'].get('ocr_confidence', 0):.2%}")
            
            # ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            if 'ml_quality_score' in result['quality_report']:
                print(f"ü§ñ ML –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {result['quality_report']['ml_quality_score']:.2%}")
            
            # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            corrections = result.get('corrections_applied', [])
            ml_corrections = [c for c in corrections if c.get('method') == 'ml_transformer']
            rule_corrections = [c for c in corrections if c.get('method') != 'ml_transformer']
            
            print(f"\n‚úèÔ∏è  –í—Å–µ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(corrections)}")
            print(f"   - –ü–æ –ø—Ä–∞–≤–∏–ª–∞–º: {len(rule_corrections)}")
            print(f"   - ML –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è: {len(ml_corrections)}")
            
            if ml_corrections:
                print("\nü§ñ ML –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:")
                for i, correction in enumerate(ml_corrections[:3], 1):
                    print(f"   {i}. '{correction['from'][:30]}...' -> '{correction['to'][:30]}...'")
            
            # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–ª—è
            print("\nüìã –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–ª—è:")
            for field_name, field_data in result['extracted_data']['critical_fields'].items():
                status = "‚úÖ" if field_data['valid'] else "‚ùå"
                print(f"   {status} {field_name.upper()}: {field_data['value'] or '(–Ω–µ –Ω–∞–π–¥–µ–Ω–æ)'} "
                      f"(–≤–∞–ª–∏–¥–Ω–æ: {field_data['valid']})")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
            import traceback
            traceback.print_exc()
    
    # –¢–µ—Å—Ç 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –§–∞–∑–∞ 1 vs –§–∞–∑–∞ 2
    print("\n\nüî¨ –¢–ï–°–¢ 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –§–∞–∑–∞ 1 vs –§–∞–∑–∞ 2")
    print("-" * 80)
    
    if pairs:
        test_file = pairs[0]['image_path']
        
        print(f"\nüìÑ –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª: {Path(test_file).name}")
        
        # –§–∞–∑–∞ 1
        print("\nüìå –§–∞–∑–∞ 1 (–±–µ–∑ ML):")
        pipeline_phase1 = DocumentPipeline(use_ml=False, use_active_learning=False)
        result_phase1 = pipeline_phase1.process(test_file, "–ê–∫—Ç –ê–û–°–†")
        
        print(f"   –ö–∞—á–µ—Å—Ç–≤–æ: {result_phase1['quality_report']['overall_quality']:.2%}")
        print(f"   –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(result_phase1.get('corrections_applied', []))}")
        
        # –§–∞–∑–∞ 2
        print("\nü§ñ –§–∞–∑–∞ 2 (—Å ML):")
        try:
            pipeline_phase2 = DocumentPipeline(use_ml=True, use_active_learning=False)
            result_phase2 = pipeline_phase2.process(test_file, "–ê–∫—Ç –ê–û–°–†")
            
            print(f"   –ö–∞—á–µ—Å—Ç–≤–æ: {result_phase2['quality_report']['overall_quality']:.2%}")
            print(f"   –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(result_phase2.get('corrections_applied', []))}")
            
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
            quality_diff = result_phase2['quality_report']['overall_quality'] - result_phase1['quality_report']['overall_quality']
            corrections_diff = len(result_phase2.get('corrections_applied', [])) - len(result_phase1.get('corrections_applied', []))
            
            print(f"\nüìä –†–∞–∑–Ω–∏—Ü–∞:")
            print(f"   –ö–∞—á–µ—Å—Ç–≤–æ: {quality_diff:+.2%}")
            print(f"   –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {corrections_diff:+d}")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è  ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: {str(e)}")
            print("   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –§–∞–∑–∞ 1")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    test_ml_components()
    
    print("\n" + "=" * 80)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    print("=" * 80)
    print("\nüí° –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: –ó–∞–ø—É—Å—Ç–∏—Ç–µ test_phase3.py –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è")


if __name__ == "__main__":
    main()
