#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –§–∞–∑—ã 3: –ê–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
"""
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ—Ä–Ω—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ –ø—É—Ç—å
app_root = Path(__file__).parent.parent
if str(app_root) not in sys.path:
    sys.path.insert(0, str(app_root))

from core.processor import DocumentPipeline
from services.active_learning import ActiveLearningSystem
from utils.dataset_loader import DatasetLoader
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_active_learning():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    print("\n" + "=" * 80)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –§–ê–ó–´ 3: –ê–ö–¢–ò–í–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï")
    print("=" * 80)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    active_learning = ActiveLearningSystem()
    
    # –¢–µ—Å—Ç 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∞–∫—Ç–∏–≤–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º
    print("\nüî¨ –¢–ï–°–¢ 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∞–∫—Ç–∏–≤–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º")
    print("-" * 80)
    
    dataset_root = Path("../–î–∞—Ç–∞—Å–µ—Ç")
    loader = DatasetLoader(str(dataset_root))
    pairs = loader.find_document_pairs("–ê–∫—Ç –ê–û–°–†")
    
    if not pairs:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        return
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    print(f"\nüìÅ –û–±—Ä–∞–±–æ—Ç–∫–∞ {min(3, len(pairs))} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    
    pipeline = DocumentPipeline(use_ml=True, use_active_learning=True)
    
    processed_docs = []
    for i, pair in enumerate(pairs[:3], 1):
        print(f"\n[{i}/{min(3, len(pairs))}] –û–±—Ä–∞–±–æ—Ç–∫–∞: {Path(pair['image_path']).name}")
        
        try:
            result = pipeline.process(
                file_path=pair['image_path'],
                template="–ê–∫—Ç –ê–û–°–†"
            )
            processed_docs.append(result)
            
            print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ (ID: {result['document_id'][:20]}...)")
            print(f"   üìä –ö–∞—á–µ—Å—Ç–≤–æ: {result['quality_report']['overall_quality']:.2%}")
            print(f"   ‚úèÔ∏è  –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(result.get('corrections_applied', []))}")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {str(e)}")
    
    # –¢–µ—Å—Ç 2: –û—Ç–ø—Ä–∞–≤–∫–∞ feedback
    print("\n\nüî¨ –¢–ï–°–¢ 2: –û—Ç–ø—Ä–∞–≤–∫–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏")
    print("-" * 80)
    
    if processed_docs:
        # –°–∏–º—É–ª—è—Ü–∏—è feedback –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        print("\nüìù –°–∏–º—É–ª—è—Ü–∏—è feedback –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è...")
        
        for doc in processed_docs[:2]:
            # Feedback –ø–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é
            corrections = doc.get('corrections_applied', [])
            if corrections:
                correction = corrections[0]
                feedback_data = {
                    "correction": {
                        "original": correction.get('from', ''),
                        "corrected": correction.get('to', ''),
                        "document_id": doc['document_id'],
                        "confidence": 1.0
                    }
                }
                
                result = active_learning.process_feedback(feedback_data)
                print(f"   ‚úÖ Feedback –ø–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –¥–ª—è {doc['document_id'][:20]}...")
                if result.get('corrections_added'):
                    print(f"      –î–æ–±–∞–≤–ª–µ–Ω–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(result['corrections_added'])}")
            
            # Feedback –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
            quality_rating = doc['quality_report']['overall_quality']
            feedback_data = {
                "quality": {
                    "document_id": doc['document_id'],
                    "rating": quality_rating,
                    "issues": [] if quality_rating > 0.8 else ["–ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"]
                }
            }
            
            active_learning.process_feedback(feedback_data)
            print(f"   ‚úÖ –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞: {quality_rating:.2%}")
    
    # –¢–µ—Å—Ç 3: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑
    print("\n\nüî¨ –¢–ï–°–¢ 3: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑")
    print("-" * 80)
    
    stats = active_learning.get_learning_statistics()
    feedback_stats = stats['feedback_statistics']
    
    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏:")
    print(f"   –í—Å–µ–≥–æ feedback –∑–∞–ø–∏—Å–µ–π: {feedback_stats['total_feedback']}")
    print(f"   –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {feedback_stats['corrections_count']}")
    print(f"   –ü—Ä–∏–º–µ–Ω–µ–Ω–æ: {feedback_stats['applied_corrections']}")
    print(f"   –û–∂–∏–¥–∞—é—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è: {feedback_stats['pending_corrections']}")
    print(f"   –†–∞–∑–º–µ—Ä –±–∞–∑—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {stats['corrections_db_size']}")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    print("\nüîç –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:")
    analysis = active_learning.analyze_feedback_patterns()
    
    if analysis['common_errors']:
        print(f"   –ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏: {len(analysis['common_errors'])}")
        for i, error in enumerate(analysis['common_errors'][:3], 1):
            print(f"      {i}. '{error['original']}' -> '{error['corrected']}' "
                  f"({error['count']} —Ä–∞–∑)")
    
    if analysis['recommendations']:
        print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        for i, rec in enumerate(analysis['recommendations'], 1):
            print(f"   {i}. {rec}")
    
    # –¢–µ—Å—Ç 4: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
    print("\n\nüî¨ –¢–ï–°–¢ 4: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π")
    print("-" * 80)
    
    candidates = active_learning.feedback_collector.get_unapplied_corrections(
        min_confidence=0.7,
        min_occurrences=1  # –î–ª—è —Ç–µ—Å—Ç–∞ —Å–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥
    )
    
    print(f"\nüìã –ö–∞–Ω–¥–∏–¥–∞—Ç—ã –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è: {len(candidates)}")
    
    if candidates:
        print("\n–ü—Ä–∏–º–µ—Ä—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤:")
        for i, candidate in enumerate(candidates[:3], 1):
            print(f"   {i}. '{candidate['original']}' -> '{candidate['corrected']}'")
            print(f"      –í—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è: {candidate['occurrences']} —Ä–∞–∑")
            print(f"      –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {candidate['avg_confidence']:.2%}")
        
        print("\nüîÑ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è...")
        active_learning._auto_update_corrections()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        new_stats = active_learning.get_learning_statistics()
        print(f"   ‚úÖ –†–∞–∑–º–µ—Ä –±–∞–∑—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {new_stats['corrections_db_size']}")
    else:
        print("   ‚ÑπÔ∏è  –ö–∞–Ω–¥–∏–¥–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã (–Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ feedback –¥–∞–Ω–Ω—ã—Ö)")
    
    # –¢–µ—Å—Ç 5: –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
    print("\n\nüî¨ –¢–ï–°–¢ 5: –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
    print("-" * 80)
    
    export_path = active_learning.export_training_data()
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã: {export_path}")
    
    print("\n" + "=" * 80)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ê–ö–¢–ò–í–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø –ó–ê–í–ï–†–®–ï–ù–û")
    print("=" * 80)
    print("\nüí° –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
    print("   - Feedback –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ")
    print("   - –ë–∞–∑–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
    print("   - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ analyze_feedback.py –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    test_active_learning()


if __name__ == "__main__":
    main()
