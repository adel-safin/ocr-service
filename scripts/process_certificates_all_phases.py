#!/usr/bin/env python3
"""
–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ –≤—Å–µ —Ç—Ä–∏ —Ñ–∞–∑—ã
–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Ñ–∞–∑—ã
"""
import sys
from pathlib import Path
import json
from datetime import datetime

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ—Ä–Ω—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ –ø—É—Ç—å
app_root = Path(__file__).parent.parent
if str(app_root) not in sys.path:
    sys.path.insert(0, str(app_root))

from core.processor import DocumentPipeline
import logging

logging.basicConfig(
    level=logging.WARNING,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def process_certificates_all_phases():
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ –≤—Å–µ —Ñ–∞–∑—ã"""
    print("=" * 100)
    print("–û–ë–†–ê–ë–û–¢–ö–ê –°–ï–†–¢–ò–§–ò–ö–ê–¢–û–í - –í–°–ï –§–ê–ó–´")
    print("=" * 100)
    
    # –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞–º–∏
    certificates_dir = Path("../—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã")
    
    if not certificates_dir.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {certificates_dir}")
        return
    
    # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö PDF —Ñ–∞–π–ª–æ–≤
    pdf_files = sorted(list(certificates_dir.glob("*.pdf")))
    
    if not pdf_files:
        print(f"‚ùå PDF —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {certificates_dir}")
        return
    
    print(f"\nüìÅ –ù–∞–π–¥–µ–Ω–æ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤: {len(pdf_files)}")
    print(f"üìã –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ –≤—Å–µ —Ñ–∞–∑—ã...\n")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Ñ–∞–∑—ã
    print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–æ–≤...")
    pipeline_phase1 = DocumentPipeline(use_ml=False, use_active_learning=False)
    pipeline_phase2 = DocumentPipeline(use_ml=True, use_active_learning=False)
    pipeline_phase3 = DocumentPipeline(use_ml=True, use_active_learning=True)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_dir = Path("data/certificates_results")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    phase1_dir = output_dir / "phase1"
    phase2_dir = output_dir / "phase2"
    phase3_dir = output_dir / "phase3"
    
    phase1_dir.mkdir(exist_ok=True)
    phase2_dir.mkdir(exist_ok=True)
    phase3_dir.mkdir(exist_ok=True)
    
    results = []
    processed = 0
    errors = 0
    
    print(f"\n‚è≥ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏...\n")
    
    for i, cert_file in enumerate(pdf_files, 1):
        print(f"[{i}/{len(pdf_files)}] {cert_file.name}")
        
        cert_result = {
            'filename': cert_file.name,
            'phase1': None,
            'phase2': None,
            'phase3': None
        }
        
        try:
            # –§–ê–ó–ê 1: –ë–∞–∑–æ–≤—ã–π OCR + –ø—Ä–∞–≤–∏–ª–∞
            print(f"   üìå –§–∞–∑–∞ 1...", end=" ")
            result1 = pipeline_phase1.process(str(cert_file), template="certificate")
            cert_result['phase1'] = result1
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –§–∞–∑—ã 1
            pages_data = result1['extracted_data'].get('pages', [])
            total_pages = result1['extracted_data'].get('total_pages', 1)
            
            phase1_file = phase1_dir / f"{cert_file.stem}_phase1.txt"
            with open(phase1_file, 'w', encoding='utf-8') as f:
                f.write(f"–°–ï–†–¢–ò–§–ò–ö–ê–¢: {cert_file.name}\n")
                f.write(f"–§–ê–ó–ê 1: –ë–ê–ó–û–í–´–ô OCR + –ü–†–ê–í–ò–õ–ê\n")
                f.write("=" * 100 + "\n")
                f.write(f"Document ID: {result1['document_id']}\n")
                f.write(f"–ö–∞—á–µ—Å—Ç–≤–æ: {result1['quality_report']['overall_quality']:.2%}\n")
                f.write(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å OCR: {result1['quality_report']['ocr_confidence']:.2%}\n")
                f.write(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(result1.get('corrections_applied', []))}\n")
                f.write(f"–í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {total_pages}\n")
                f.write("\n" + "=" * 100 + "\n")
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º
                if pages_data and len(pages_data) > 1:
                    f.write("–†–ê–°–ü–û–ó–ù–ê–ù–ù–´–ô –¢–ï–ö–°–¢ –ü–û –°–¢–†–ê–ù–ò–¶–ê–ú:\n")
                    f.write("=" * 100 + "\n")
                    for page_info in pages_data:
                        page_num = page_info.get('page_number', 1)
                        page_text = page_info.get('text', '')
                        page_conf = page_info.get('confidence', 0.0)
                        f.write(f"\n--- –°–¢–†–ê–ù–ò–¶–ê {page_num} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {page_conf:.2%}) ---\n")
                        f.write(page_text)
                        f.write("\n")
                else:
                    f.write("–ü–û–õ–ù–´–ô –¢–ï–ö–°–¢:\n")
                    f.write("=" * 100 + "\n")
                    f.write(result1['extracted_data']['full_text'])
                    f.write("\n" + "=" * 100 + "\n")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–µ—Å–ª–∏ –±–æ–ª—å—à–µ 1 —Å—Ç—Ä–∞–Ω–∏—Ü—ã)
            if pages_data and len(pages_data) > 1:
                pages_dir = phase1_dir / f"{cert_file.stem}_pages"
                pages_dir.mkdir(exist_ok=True)
                
                for page_info in pages_data:
                    page_num = page_info.get('page_number', 1)
                    page_text = page_info.get('text', '')
                    page_file = pages_dir / f"page_{page_num:03d}.txt"
                    
                    with open(page_file, 'w', encoding='utf-8') as pf:
                        pf.write(f"–°–ï–†–¢–ò–§–ò–ö–ê–¢: {cert_file.name}\n")
                        pf.write(f"–§–ê–ó–ê 1: –ë–ê–ó–û–í–´–ô OCR + –ü–†–ê–í–ò–õ–ê\n")
                        pf.write(f"–°–¢–†–ê–ù–ò–¶–ê: {page_num} –∏–∑ {total_pages}\n")
                        pf.write(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å OCR: {page_info.get('confidence', 0.0):.2%}\n")
                        pf.write("\n" + "=" * 100 + "\n")
                        pf.write("–¢–ï–ö–°–¢ –°–¢–†–ê–ù–ò–¶–´:\n")
                        pf.write("=" * 100 + "\n")
                        pf.write(page_text)
                        pf.write("\n" + "=" * 100 + "\n")
            
            print(f"‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ: {result1['quality_report']['overall_quality']:.2%}")
            
            # –§–ê–ó–ê 2: –° ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
            print(f"   ü§ñ –§–∞–∑–∞ 2...", end=" ")
            result2 = pipeline_phase2.process(str(cert_file), template="certificate")
            cert_result['phase2'] = result2
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –§–∞–∑—ã 2
            pages_data2 = result2['extracted_data'].get('pages', [])
            total_pages2 = result2['extracted_data'].get('total_pages', 1)
            
            phase2_file = phase2_dir / f"{cert_file.stem}_phase2.txt"
            with open(phase2_file, 'w', encoding='utf-8') as f:
                f.write(f"–°–ï–†–¢–ò–§–ò–ö–ê–¢: {cert_file.name}\n")
                f.write(f"–§–ê–ó–ê 2: –ú–ê–®–ò–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï\n")
                f.write("=" * 100 + "\n")
                f.write(f"Document ID: {result2['document_id']}\n")
                f.write(f"–ö–∞—á–µ—Å—Ç–≤–æ: {result2['quality_report']['overall_quality']:.2%}\n")
                f.write(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å OCR: {result2['quality_report']['ocr_confidence']:.2%}\n")
                f.write(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(result2.get('corrections_applied', []))}\n")
                f.write(f"–í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {total_pages2}\n")
                f.write("\n" + "=" * 100 + "\n")
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º
                if pages_data2 and len(pages_data2) > 1:
                    f.write("–†–ê–°–ü–û–ó–ù–ê–ù–ù–´–ô –¢–ï–ö–°–¢ –ü–û –°–¢–†–ê–ù–ò–¶–ê–ú:\n")
                    f.write("=" * 100 + "\n")
                    for page_info in pages_data2:
                        page_num = page_info.get('page_number', 1)
                        page_text = page_info.get('text', '')
                        page_conf = page_info.get('confidence', 0.0)
                        f.write(f"\n--- –°–¢–†–ê–ù–ò–¶–ê {page_num} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {page_conf:.2%}) ---\n")
                        f.write(page_text)
                        f.write("\n")
                else:
                    f.write("–ü–û–õ–ù–´–ô –¢–ï–ö–°–¢:\n")
                    f.write("=" * 100 + "\n")
                    f.write(result2['extracted_data']['full_text'])
                    f.write("\n" + "=" * 100 + "\n")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–µ—Å–ª–∏ –±–æ–ª—å—à–µ 1 —Å—Ç—Ä–∞–Ω–∏—Ü—ã)
            if pages_data2 and len(pages_data2) > 1:
                pages_dir = phase2_dir / f"{cert_file.stem}_pages"
                pages_dir.mkdir(exist_ok=True)
                
                for page_info in pages_data2:
                    page_num = page_info.get('page_number', 1)
                    page_text = page_info.get('text', '')
                    page_file = pages_dir / f"page_{page_num:03d}.txt"
                    
                    with open(page_file, 'w', encoding='utf-8') as pf:
                        pf.write(f"–°–ï–†–¢–ò–§–ò–ö–ê–¢: {cert_file.name}\n")
                        pf.write(f"–§–ê–ó–ê 2: –ú–ê–®–ò–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï\n")
                        pf.write(f"–°–¢–†–ê–ù–ò–¶–ê: {page_num} –∏–∑ {total_pages2}\n")
                        pf.write(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å OCR: {page_info.get('confidence', 0.0):.2%}\n")
                        pf.write("\n" + "=" * 100 + "\n")
                        pf.write("–¢–ï–ö–°–¢ –°–¢–†–ê–ù–ò–¶–´:\n")
                        pf.write("=" * 100 + "\n")
                        pf.write(page_text)
                        pf.write("\n" + "=" * 100 + "\n")
            
            print(f"‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ: {result2['quality_report']['overall_quality']:.2%}")
            
            # –§–ê–ó–ê 3: –° –∞–∫—Ç–∏–≤–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º
            print(f"   üîÑ –§–∞–∑–∞ 3...", end=" ")
            result3 = pipeline_phase3.process(str(cert_file), template="certificate")
            cert_result['phase3'] = result3
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –§–∞–∑—ã 3
            pages_data3 = result3['extracted_data'].get('pages', [])
            total_pages3 = result3['extracted_data'].get('total_pages', 1)
            
            phase3_file = phase3_dir / f"{cert_file.stem}_phase3.txt"
            with open(phase3_file, 'w', encoding='utf-8') as f:
                f.write(f"–°–ï–†–¢–ò–§–ò–ö–ê–¢: {cert_file.name}\n")
                f.write(f"–§–ê–ó–ê 3: –ê–ö–¢–ò–í–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï\n")
                f.write("=" * 100 + "\n")
                f.write(f"Document ID: {result3['document_id']}\n")
                f.write(f"–ö–∞—á–µ—Å—Ç–≤–æ: {result3['quality_report']['overall_quality']:.2%}\n")
                f.write(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å OCR: {result3['quality_report']['ocr_confidence']:.2%}\n")
                f.write(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(result3.get('corrections_applied', []))}\n")
                f.write(f"–í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {total_pages3}\n")
                f.write("\n" + "=" * 100 + "\n")
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º
                if pages_data3 and len(pages_data3) > 1:
                    f.write("–†–ê–°–ü–û–ó–ù–ê–ù–ù–´–ô –¢–ï–ö–°–¢ –ü–û –°–¢–†–ê–ù–ò–¶–ê–ú:\n")
                    f.write("=" * 100 + "\n")
                    for page_info in pages_data3:
                        page_num = page_info.get('page_number', 1)
                        page_text = page_info.get('text', '')
                        page_conf = page_info.get('confidence', 0.0)
                        f.write(f"\n--- –°–¢–†–ê–ù–ò–¶–ê {page_num} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {page_conf:.2%}) ---\n")
                        f.write(page_text)
                        f.write("\n")
                else:
                    f.write("–ü–û–õ–ù–´–ô –¢–ï–ö–°–¢:\n")
                    f.write("=" * 100 + "\n")
                    f.write(result3['extracted_data']['full_text'])
                    f.write("\n" + "=" * 100 + "\n")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–µ—Å–ª–∏ –±–æ–ª—å—à–µ 1 —Å—Ç—Ä–∞–Ω–∏—Ü—ã)
            if pages_data3 and len(pages_data3) > 1:
                pages_dir = phase3_dir / f"{cert_file.stem}_pages"
                pages_dir.mkdir(exist_ok=True)
                
                for page_info in pages_data3:
                    page_num = page_info.get('page_number', 1)
                    page_text = page_info.get('text', '')
                    page_file = pages_dir / f"page_{page_num:03d}.txt"
                    
                    with open(page_file, 'w', encoding='utf-8') as pf:
                        pf.write(f"–°–ï–†–¢–ò–§–ò–ö–ê–¢: {cert_file.name}\n")
                        pf.write(f"–§–ê–ó–ê 3: –ê–ö–¢–ò–í–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï\n")
                        pf.write(f"–°–¢–†–ê–ù–ò–¶–ê: {page_num} –∏–∑ {total_pages3}\n")
                        pf.write(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å OCR: {page_info.get('confidence', 0.0):.2%}\n")
                        pf.write("\n" + "=" * 100 + "\n")
                        pf.write("–¢–ï–ö–°–¢ –°–¢–†–ê–ù–ò–¶–´:\n")
                        pf.write("=" * 100 + "\n")
                        pf.write(page_text)
                        pf.write("\n" + "=" * 100 + "\n")
            
            print(f"‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ: {result3['quality_report']['overall_quality']:.2%}")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            result_data = {
                'filename': cert_file.name,
                'phase1': {
                    'document_id': result1['document_id'],
                    'quality': result1['quality_report']['overall_quality'],
                    'ocr_confidence': result1['quality_report']['ocr_confidence'],
                    'corrections_count': len(result1.get('corrections_applied', [])),
                    'text_length': len(result1['extracted_data']['full_text']),
                    'text_file': str(phase1_file.relative_to(Path('data')))
                },
                'phase2': {
                    'document_id': result2['document_id'],
                    'quality': result2['quality_report']['overall_quality'],
                    'ocr_confidence': result2['quality_report']['ocr_confidence'],
                    'corrections_count': len(result2.get('corrections_applied', [])),
                    'text_length': len(result2['extracted_data']['full_text']),
                    'text_file': str(phase2_file.relative_to(Path('data')))
                },
                'phase3': {
                    'document_id': result3['document_id'],
                    'quality': result3['quality_report']['overall_quality'],
                    'ocr_confidence': result3['quality_report']['ocr_confidence'],
                    'corrections_count': len(result3.get('corrections_applied', [])),
                    'text_length': len(result3['extracted_data']['full_text']),
                    'text_file': str(phase3_file.relative_to(Path('data')))
                },
                'processing_timestamp': datetime.now().isoformat()
            }
            
            results.append(result_data)
            processed += 1
            
            print(f"   ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ\n")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {str(e)}\n")
            errors += 1
            import traceback
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {cert_file}: {traceback.format_exc()}")
            continue
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
    summary = {
        'total_certificates': len(pdf_files),
        'processed': processed,
        'errors': errors,
        'results': results,
        'statistics': {},
        'processing_timestamp': datetime.now().isoformat()
    }
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if results:
        # –§–∞–∑–∞ 1
        phase1_qualities = [r['phase1']['quality'] for r in results]
        phase1_ocr_conf = [r['phase1']['ocr_confidence'] for r in results]
        phase1_corrections = [r['phase1']['corrections_count'] for r in results]
        
        # –§–∞–∑–∞ 2
        phase2_qualities = [r['phase2']['quality'] for r in results]
        phase2_ocr_conf = [r['phase2']['ocr_confidence'] for r in results]
        phase2_corrections = [r['phase2']['corrections_count'] for r in results]
        
        # –§–∞–∑–∞ 3
        phase3_qualities = [r['phase3']['quality'] for r in results]
        phase3_ocr_conf = [r['phase3']['ocr_confidence'] for r in results]
        phase3_corrections = [r['phase3']['corrections_count'] for r in results]
        
        summary['statistics'] = {
            'phase1': {
                'avg_quality': sum(phase1_qualities) / len(phase1_qualities),
                'avg_ocr_confidence': sum(phase1_ocr_conf) / len(phase1_ocr_conf),
                'total_corrections': sum(phase1_corrections),
                'avg_corrections': sum(phase1_corrections) / len(phase1_corrections)
            },
            'phase2': {
                'avg_quality': sum(phase2_qualities) / len(phase2_qualities),
                'avg_ocr_confidence': sum(phase2_ocr_conf) / len(phase2_ocr_conf),
                'total_corrections': sum(phase2_corrections),
                'avg_corrections': sum(phase2_corrections) / len(phase2_corrections)
            },
            'phase3': {
                'avg_quality': sum(phase3_qualities) / len(phase3_qualities),
                'avg_ocr_confidence': sum(phase3_ocr_conf) / len(phase3_ocr_conf),
                'total_corrections': sum(phase3_corrections),
                'avg_corrections': sum(phase3_corrections) / len(phase3_corrections)
            }
        }
    
    summary_file = output_dir / "summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print("\n" + "=" * 100)
    print("–ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 100)
    print(f"\nüìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}/{len(pdf_files)}")
    print(f"‚ùå –û—à–∏–±–æ–∫: {errors}")
    
    if summary['statistics']:
        stats = summary['statistics']
        print(f"\nüìà –§–ê–ó–ê 1 (–ë–∞–∑–æ–≤—ã–π OCR + –ø—Ä–∞–≤–∏–ª–∞):")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ: {stats['phase1']['avg_quality']:.2%}")
        print(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å OCR: {stats['phase1']['avg_ocr_confidence']:.2%}")
        print(f"   –í—Å–µ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {stats['phase1']['total_corrections']} (–≤ —Å—Ä–µ–¥–Ω–µ–º {stats['phase1']['avg_corrections']:.1f})")
        
        print(f"\nü§ñ –§–ê–ó–ê 2 (–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ):")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ: {stats['phase2']['avg_quality']:.2%}")
        print(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å OCR: {stats['phase2']['avg_ocr_confidence']:.2%}")
        print(f"   –í—Å–µ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {stats['phase2']['total_corrections']} (–≤ —Å—Ä–µ–¥–Ω–µ–º {stats['phase2']['avg_corrections']:.1f})")
        
        print(f"\nüîÑ –§–ê–ó–ê 3 (–ê–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ):")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ: {stats['phase3']['avg_quality']:.2%}")
        print(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å OCR: {stats['phase3']['avg_ocr_confidence']:.2%}")
        print(f"   –í—Å–µ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {stats['phase3']['total_corrections']} (–≤ —Å—Ä–µ–¥–Ω–µ–º {stats['phase3']['avg_corrections']:.1f})")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
        print(f"\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –§–ê–ó:")
        print(f"   –ö–∞—á–µ—Å—Ç–≤–æ: –§–∞–∑–∞ 1: {stats['phase1']['avg_quality']:.2%} | –§–∞–∑–∞ 2: {stats['phase2']['avg_quality']:.2%} | –§–∞–∑–∞ 3: {stats['phase3']['avg_quality']:.2%}")
        print(f"   –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: –§–∞–∑–∞ 1: {stats['phase1']['total_corrections']} | –§–∞–∑–∞ 2: {stats['phase2']['total_corrections']} | –§–∞–∑–∞ 3: {stats['phase3']['total_corrections']}")
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    print(f"   - –§–∞–∑–∞ 1: {phase1_dir}/")
    print(f"   - –§–∞–∑–∞ 2: {phase2_dir}/")
    print(f"   - –§–∞–∑–∞ 3: {phase3_dir}/")
    print(f"   - –°–≤–æ–¥–∫–∞: {summary_file}")
    
    print("\n" + "=" * 100)
    print("–û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
    print("=" * 100)
    
    return results


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    results = process_certificates_all_phases()
    
    if results:
        print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(results)} —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø–∞–ø–∫–µ: data/certificates_results/")


if __name__ == "__main__":
    main()

